{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessor:\n",
    "    def __init__(self, file_path):\n",
    "        self.data = pd.read_csv(file_path, encoding='cp949', index_col=0)\n",
    "\n",
    "    def encode_working(self):\n",
    "        self.data['working_encoded'] = self.data['working'].map({'가동': 1, '정지': 0})\n",
    "\n",
    "    def preprocess_datetime(self):\n",
    "        self.data['datetime'] = pd.to_datetime(self.data['date'] + ' ' + self.data['time'])\n",
    "        self.data['datetime_int'] = self.data['datetime'].astype(np.int64) // 10**9\n",
    "\n",
    "    def remove_unnecessary_columns(self):\n",
    "        columns_to_drop = ['count', 'EMS_operation_time', 'mold_code']\n",
    "        self.data = self.data.drop(columns_to_drop, axis=1, errors='ignore')\n",
    "        self.data = self.data.select_dtypes(include=[np.number])\n",
    "\n",
    "    def remove_missing_values(self):\n",
    "        if 'molten_volume' in self.data.columns:\n",
    "            self.data.drop('molten_volume', axis=1, inplace=True)\n",
    "        self.data.dropna(axis=0, inplace=True)\n",
    "        self.data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    def remove_outliers(self, percentile_range=(0.1, 99.9)):\n",
    "        for col in self.data.select_dtypes(include=np.number).columns:\n",
    "            if col != 'passorfail':\n",
    "                lower = np.percentile(self.data[col], percentile_range[0])\n",
    "                upper = np.percentile(self.data[col], percentile_range[1])\n",
    "                self.data = self.data[(self.data[col] >= lower) & (self.data[col] <= upper)]\n",
    "        self.data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    def perform_feature_selection(self):\n",
    "        t_test_results = []\n",
    "        for col in self.data.columns:\n",
    "            if col != 'passorfail':\n",
    "                t_stat, p_value = scipy.stats.ttest_ind(\n",
    "                    self.data[self.data['passorfail'] == 1][col],\n",
    "                    self.data[self.data['passorfail'] == 0][col],\n",
    "                    equal_var=False\n",
    "                )\n",
    "                if p_value < 0.05:\n",
    "                    t_test_results.append(col)\n",
    "        t_test_results.append('passorfail')\n",
    "        self.data = self.data[t_test_results]\n",
    "\n",
    "    def get_processed_data(self):\n",
    "        return self.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleStacker1:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        self.scaler = StandardScaler()\n",
    "        self.X_train_scaled = self.scaler.fit_transform(self.X_train)\n",
    "        self.X_test_scaled = self.scaler.transform(self.X_test)\n",
    "\n",
    "        # 1층의 KNN 제거\n",
    "        self.factory_deterministic_candidates = [\"Logistic Regression\", \"GaussianNB\"]\n",
    "        self.factory_complex_candidates = [\"Extra Trees\", \"KNN\"]\n",
    "\n",
    "    def create_model(self, model_name):\n",
    "        model_dict = {\n",
    "            \"Logistic Regression\": LogisticRegression(),\n",
    "            \"GaussianNB\": GaussianNB(),\n",
    "            \"KNN\": KNeighborsClassifier(),\n",
    "            \"Extra Trees\": ExtraTreesClassifier()\n",
    "        }\n",
    "        return model_dict[model_name]\n",
    "\n",
    "    def evaluate_individual_model(self, model, X_train, X_test, y_train, y_test, model_name, layer_name):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else y_pred\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba) if hasattr(model, 'predict_proba') else None\n",
    "        fpr = confusion_matrix(y_test, y_pred)[0][1] / sum(confusion_matrix(y_test, y_pred)[0])\n",
    "\n",
    "        return {\n",
    "            'Model': model_name,\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1 Score': f1,\n",
    "            'ROC AUC': roc_auc,\n",
    "            'FPR': fpr\n",
    "        }\n",
    "\n",
    "    def run_all_combinations(self):\n",
    "        stage_results = []\n",
    "        stage_number = 1\n",
    "\n",
    "        for fd_model in self.factory_deterministic_candidates:\n",
    "            for fc_model in self.factory_complex_candidates:\n",
    "                print(f\"\\n=== Stage {stage_number} ===\")\n",
    "\n",
    "                # 각 층의 모델 초기화\n",
    "                layer_configs = {\n",
    "                    \"Factory Deterministic\": fd_model,\n",
    "                    \"Factory Complex\": fc_model,\n",
    "                }\n",
    "\n",
    "                # 각 층의 모델을 평가\n",
    "                layer_results = {}\n",
    "                estimators = []\n",
    "                for layer_name, model_name in layer_configs.items():\n",
    "                    model = self.create_model(model_name)\n",
    "                    metrics = self.evaluate_individual_model(\n",
    "                        model, self.X_train_scaled, self.X_test_scaled,\n",
    "                        self.y_train, self.y_test, model_name, layer_name\n",
    "                    )\n",
    "                    layer_results[f\"{layer_name} Model\"] = model_name\n",
    "                    layer_results[f\"{layer_name} Accuracy\"] = metrics['Accuracy']\n",
    "                    layer_results[f\"{layer_name} Precision\"] = metrics['Precision']\n",
    "                    layer_results[f\"{layer_name} Recall\"] = metrics['Recall']\n",
    "                    layer_results[f\"{layer_name} F1 Score\"] = metrics['F1 Score']\n",
    "                    layer_results[f\"{layer_name} ROC AUC\"] = metrics['ROC AUC']\n",
    "                    layer_results[f\"{layer_name} FPR\"] = metrics['FPR']\n",
    "                    estimators.append((model_name, model))\n",
    "\n",
    "                # 스태킹을 위한 최종 메타 모델\n",
    "                stacking_clf = StackingClassifier(\n",
    "                    estimators=estimators,\n",
    "                    final_estimator=XGBClassifier(),\n",
    "                    cv=5\n",
    "                )\n",
    "\n",
    "                # 최종 메타 모델 평가\n",
    "                stacking_clf.fit(self.X_train_scaled, self.y_train)\n",
    "                y_pred = stacking_clf.predict(self.X_test_scaled)\n",
    "                y_pred_proba = stacking_clf.predict_proba(self.X_test_scaled)[:, 1]\n",
    "\n",
    "                # 스태킹 모델 성능 결과 저장\n",
    "                layer_results['Stage'] = stage_number\n",
    "                layer_results['Stacked Model Accuracy'] = accuracy_score(self.y_test, y_pred)\n",
    "                layer_results['Stacked Model Precision'] = precision_score(self.y_test, y_pred)\n",
    "                layer_results['Stacked Model Recall'] = recall_score(self.y_test, y_pred)\n",
    "                layer_results['Stacked Model F1 Score'] = f1_score(self.y_test, y_pred)\n",
    "                layer_results['Stacked Model ROC AUC'] = roc_auc_score(self.y_test, y_pred_proba)\n",
    "                layer_results['Stacked Model FPR'] = confusion_matrix(self.y_test, y_pred)[0][1] / sum(confusion_matrix(self.y_test, y_pred)[0])\n",
    "\n",
    "                print(\"\\n--- Stacked Model Performance ---\")\n",
    "                print(f\"Accuracy: {layer_results['Stacked Model Accuracy']:.4f}, Precision: {layer_results['Stacked Model Precision']:.4f}, Recall: {layer_results['Stacked Model Recall']:.4f}, F1 Score: {layer_results['Stacked Model F1 Score']:.4f}, ROC AUC: {layer_results['Stacked Model ROC AUC']:.4f}, FPR: {layer_results['Stacked Model FPR']:.4f}\")\n",
    "\n",
    "                # 결과 저장\n",
    "                stage_results.append(layer_results)\n",
    "                stage_number += 1\n",
    "\n",
    "        # 결과를 데이터프레임으로 변환하여 반환\n",
    "        results_df = pd.DataFrame(stage_results)\n",
    "        results_df.columns = [\n",
    "            'Stage', 'Layer 1 Model (Factory Deterministic)', 'Layer 1 Accuracy', 'Layer 1 Precision', 'Layer 1 Recall', 'Layer 1 F1 Score',\n",
    "            'Layer 1 ROC AUC', 'Layer 1 FPR', 'Layer 2 Model (Factory Complex)', 'Layer 2 Accuracy', 'Layer 2 Precision',\n",
    "            'Layer 2 Recall', 'Layer 2 F1 Score', 'Layer 2 ROC AUC', 'Layer 2 FPR', 'Stacked Model Accuracy',\n",
    "            'Stacked Model Precision', 'Stacked Model Recall', 'Stacked Model F1 Score', 'Stacked Model ROC AUC', 'Stacked Model FPR'\n",
    "        ]\n",
    "\n",
    "        return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleStacker2:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        self.scaler = StandardScaler()\n",
    "        self.X_train_scaled = self.scaler.fit_transform(self.X_train)\n",
    "        self.X_test_scaled = self.scaler.transform(self.X_test)\n",
    "\n",
    "        # 3, 4층의 후보 모델만 사용\n",
    "        self.command_deterministic_candidates = [\"Random Forest\", \"XGBoost\", \"AdaBoost\"]\n",
    "        self.command_complex_candidates = [\"LightGBM\", \"CatBoost\", \"GBM\", \"MLP\"]\n",
    "\n",
    "    def create_model(self, model_name):\n",
    "        model_dict = {\n",
    "            \"Random Forest\": RandomForestClassifier(),\n",
    "            \"XGBoost\": XGBClassifier(),\n",
    "            \"AdaBoost\": AdaBoostClassifier(),\n",
    "            \"LightGBM\": LGBMClassifier(),\n",
    "            \"CatBoost\": CatBoostClassifier(verbose=0),\n",
    "            \"GBM\": LGBMClassifier(),\n",
    "            \"MLP\": MLPClassifier()\n",
    "        }\n",
    "        return model_dict[model_name]\n",
    "\n",
    "    def evaluate_individual_model(self, model, X_train, X_test, y_train, y_test, model_name, layer_name):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else y_pred\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba) if hasattr(model, 'predict_proba') else None\n",
    "        fpr = confusion_matrix(y_test, y_pred)[0][1] / sum(confusion_matrix(y_test, y_pred)[0])\n",
    "\n",
    "        return {\n",
    "            'Model': model_name,\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1 Score': f1,\n",
    "            'ROC AUC': roc_auc,\n",
    "            'FPR': fpr\n",
    "        }\n",
    "\n",
    "    def run_all_combinations(self):\n",
    "        stage_results = []\n",
    "        stage_number = 1\n",
    "\n",
    "        for cd_model in self.command_deterministic_candidates:\n",
    "            for cc_model in self.command_complex_candidates:\n",
    "                print(f\"\\n=== Stage {stage_number} ===\")\n",
    "\n",
    "                # 각 층의 모델 초기화\n",
    "                layer_configs = {\n",
    "                    \"Command Deterministic\": cd_model,\n",
    "                    \"Command Complex\": cc_model,\n",
    "                }\n",
    "\n",
    "                # 각 층의 모델을 평가\n",
    "                layer_results = {}\n",
    "                estimators = []\n",
    "                for layer_name, model_name in layer_configs.items():\n",
    "                    model = self.create_model(model_name)\n",
    "                    metrics = self.evaluate_individual_model(\n",
    "                        model, self.X_train_scaled, self.X_test_scaled,\n",
    "                        self.y_train, self.y_test, model_name, layer_name\n",
    "                    )\n",
    "                    layer_results[f\"{layer_name} Model\"] = model_name\n",
    "                    layer_results[f\"{layer_name} Accuracy\"] = metrics['Accuracy']\n",
    "                    layer_results[f\"{layer_name} Precision\"] = metrics['Precision']\n",
    "                    layer_results[f\"{layer_name} Recall\"] = metrics['Recall']\n",
    "                    layer_results[f\"{layer_name} F1 Score\"] = metrics['F1 Score']\n",
    "                    layer_results[f\"{layer_name} ROC AUC\"] = metrics['ROC AUC']\n",
    "                    layer_results[f\"{layer_name} FPR\"] = metrics['FPR']\n",
    "                    estimators.append((model_name, model))\n",
    "\n",
    "                # 스태킹을 위한 최종 메타 모델\n",
    "                stacking_clf = StackingClassifier(\n",
    "                    estimators=estimators,\n",
    "                    final_estimator=XGBClassifier(),\n",
    "                    cv=5\n",
    "                )\n",
    "\n",
    "                # 최종 메타 모델 평가\n",
    "                stacking_clf.fit(self.X_train_scaled, self.y_train)\n",
    "                y_pred = stacking_clf.predict(self.X_test_scaled)\n",
    "                y_pred_proba = stacking_clf.predict_proba(self.X_test_scaled)[:, 1]\n",
    "\n",
    "                # 스태킹 모델 성능 결과 저장\n",
    "                layer_results['Stage'] = stage_number\n",
    "                layer_results['Stacked Model Accuracy'] = accuracy_score(self.y_test, y_pred)\n",
    "                layer_results['Stacked Model Precision'] = precision_score(self.y_test, y_pred)\n",
    "                layer_results['Stacked Model Recall'] = recall_score(self.y_test, y_pred)\n",
    "                layer_results['Stacked Model F1 Score'] = f1_score(self.y_test, y_pred)\n",
    "                layer_results['Stacked Model ROC AUC'] = roc_auc_score(self.y_test, y_pred_proba)\n",
    "                layer_results['Stacked Model FPR'] = confusion_matrix(self.y_test, y_pred)[0][1] / sum(confusion_matrix(self.y_test, y_pred)[0])\n",
    "\n",
    "                print(\"\\n--- Stacked Model Performance ---\")\n",
    "                print(f\"Accuracy: {layer_results['Stacked Model Accuracy']:.4f}, Precision: {layer_results['Stacked Model Precision']:.4f}, Recall: {layer_results['Stacked Model Recall']:.4f}, F1 Score: {layer_results['Stacked Model F1 Score']:.4f}, ROC AUC: {layer_results['Stacked Model ROC AUC']:.4f}, FPR: {layer_results['Stacked Model FPR']:.4f}\")\n",
    "\n",
    "                # 결과 저장\n",
    "                stage_results.append(layer_results)\n",
    "                stage_number += 1\n",
    "\n",
    "        # 결과를 데이터프레임으로 변환하여 반환\n",
    "        results_df = pd.DataFrame(stage_results)\n",
    "        results_df.columns = [\n",
    "            'Stage', 'Layer 3 Model (Command Deterministic)', 'Layer 3 Accuracy', 'Layer 3 Precision', 'Layer 3 Recall', 'Layer 3 F1 Score',\n",
    "            'Layer 3 ROC AUC', 'Layer 3 FPR', 'Layer 4 Model (Command Complex)', 'Layer 4 Accuracy', 'Layer 4 Precision',\n",
    "            'Layer 4 Recall', 'Layer 4 F1 Score', 'Layer 4 ROC AUC', 'Layer 4 FPR', 'Stacked Model Accuracy',\n",
    "            'Stacked Model Precision', 'Stacked Model Recall', 'Stacked Model F1 Score', 'Stacked Model ROC AUC', 'Stacked Model FPR'\n",
    "        ]\n",
    "\n",
    "        return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleStacker3:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        self.scaler = StandardScaler()\n",
    "        self.X_train_scaled = self.scaler.fit_transform(self.X_train)\n",
    "        self.X_test_scaled = self.scaler.transform(self.X_test)\n",
    "\n",
    "        # 각 층의 후보 모델\n",
    "        self.factory_deterministic_candidates = [\"Logistic Regression\", \"GaussianNB\", \"KNN\"]\n",
    "        self.factory_complex_candidates = [\"Extra Trees\", \"KNN\"]\n",
    "        self.command_deterministic_candidates = [\"Random Forest\", \"XGBoost\", \"AdaBoost\"]\n",
    "        self.command_complex_candidates = [\"LightGBM\", \"CatBoost\", \"GBM\", \"MLP\"]\n",
    "\n",
    "    def create_model(self, model_name):\n",
    "        model_dict = {\n",
    "            \"Logistic Regression\": LogisticRegression(),\n",
    "            \"GaussianNB\": GaussianNB(),\n",
    "            \"KNN\": KNeighborsClassifier(),\n",
    "            \"Extra Trees\": ExtraTreesClassifier(),\n",
    "            \"Random Forest\": RandomForestClassifier(),\n",
    "            \"XGBoost\": XGBClassifier(),\n",
    "            \"AdaBoost\": AdaBoostClassifier(),\n",
    "            \"LightGBM\": LGBMClassifier(),\n",
    "            \"CatBoost\": CatBoostClassifier(verbose=0),\n",
    "            \"GBM\": LGBMClassifier(),\n",
    "            \"MLP\": MLPClassifier()\n",
    "        }\n",
    "        return model_dict[model_name]\n",
    "\n",
    "    def evaluate_individual_model(self, model, X_train, X_test, y_train, y_test, model_name, layer_name):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else y_pred\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba) if hasattr(model, 'predict_proba') else None\n",
    "        fpr = confusion_matrix(y_test, y_pred)[0][1] / sum(confusion_matrix(y_test, y_pred)[0])\n",
    "\n",
    "        print(f\"Layer: {layer_name}, Model: {model_name}\")\n",
    "        if roc_auc is not None:\n",
    "            print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}, ROC AUC: {roc_auc:.4f}, FPR: {fpr:.4f}\")\n",
    "        else:\n",
    "            print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}, ROC AUC: N/A, FPR: {fpr:.4f}\")\n",
    "\n",
    "        return {\n",
    "            'Layer': layer_name,\n",
    "            'Model': model_name,\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1 Score': f1,\n",
    "            'ROC AUC': roc_auc,\n",
    "            'FPR': fpr\n",
    "        }\n",
    "\n",
    "    def run_all_combinations(self):\n",
    "        stage_results = []\n",
    "        stage_number = 1\n",
    "\n",
    "        for fd_model in self.factory_deterministic_candidates:\n",
    "            for fc_model in self.factory_complex_candidates:\n",
    "                for cd_model in self.command_deterministic_candidates:\n",
    "                    for cc_model in self.command_complex_candidates:\n",
    "                        print(f\"\\n=== Stage {stage_number} ===\")\n",
    "\n",
    "                        # 각 층의 모델 초기화\n",
    "                        layer_configs = {\n",
    "                            \"Factory Deterministic\": fd_model,\n",
    "                            \"Factory Complex\": fc_model,\n",
    "                            \"Command Deterministic\": cd_model,\n",
    "                            \"Command Complex\": cc_model\n",
    "                        }\n",
    "\n",
    "                        # 각 층의 모델을 평가\n",
    "                        estimators = []\n",
    "                        for layer_name, model_name in layer_configs.items():\n",
    "                            model = self.create_model(model_name)\n",
    "                            metrics = self.evaluate_individual_model(\n",
    "                                model, self.X_train_scaled, self.X_test_scaled,\n",
    "                                self.y_train, self.y_test, model_name, layer_name\n",
    "                            )\n",
    "                            estimators.append((model_name, model))\n",
    "\n",
    "                        # 스태킹을 위한 최종 메타 모델\n",
    "                        stacking_clf = StackingClassifier(\n",
    "                            estimators=estimators,\n",
    "                            final_estimator=XGBClassifier(),\n",
    "                            cv=5\n",
    "                        )\n",
    "\n",
    "                        # 최종 메타 모델 평가\n",
    "                        stacking_clf.fit(self.X_train_scaled, self.y_train)\n",
    "                        y_pred = stacking_clf.predict(self.X_test_scaled)\n",
    "                        y_pred_proba = stacking_clf.predict_proba(self.X_test_scaled)[:, 1]\n",
    "\n",
    "                        accuracy = accuracy_score(self.y_test, y_pred)\n",
    "                        precision = precision_score(self.y_test, y_pred)\n",
    "                        recall = recall_score(self.y_test, y_pred)\n",
    "                        f1 = f1_score(self.y_test, y_pred)\n",
    "                        roc_auc = roc_auc_score(self.y_test, y_pred_proba)\n",
    "                        fpr = confusion_matrix(self.y_test, y_pred)[0][1] / sum(confusion_matrix(self.y_test, y_pred)[0])\n",
    "\n",
    "                        print(\"\\n--- Stacked Model Performance ---\")\n",
    "                        print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}, ROC AUC: {roc_auc:.4f}, FPR: {fpr:.4f}\")\n",
    "\n",
    "                        # 결과 저장\n",
    "                        stage_results.append({\n",
    "                            'Stage': stage_number,\n",
    "                            'Factory Deterministic': fd_model,\n",
    "                            'Factory Complex': fc_model,\n",
    "                            'Command Deterministic': cd_model,\n",
    "                            'Command Complex': cc_model,\n",
    "                            'Stacked Model': 'XGBoost',\n",
    "                            'Accuracy': accuracy,\n",
    "                            'Precision': precision,\n",
    "                            'Recall': recall,\n",
    "                            'F1 Score': f1,\n",
    "                            'ROC AUC': roc_auc,\n",
    "                            'FPR': fpr\n",
    "                        })\n",
    "\n",
    "                        stage_number += 1\n",
    "\n",
    "        return pd.DataFrame(stage_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stacked_model_performance(results_df):\n",
    "    # 각 성능 지표를 비교할 수 있도록 막대그래프 생성\n",
    "    metrics = ['Stacked Model Accuracy', 'Stacked Model Precision', 'Stacked Model Recall',\n",
    "               'Stacked Model F1 Score', 'Stacked Model ROC AUC']\n",
    "\n",
    "    # 각 조합(스테이지)별로 모든 성능 지표를 비교하는 그래프\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # 막대의 위치와 너비 설정\n",
    "    stages = results_df['Stage']\n",
    "    bar_width = 0.15\n",
    "    index = np.arange(len(stages))\n",
    "\n",
    "    # 각 성능 지표에 대한 막대 그래프\n",
    "    for i, metric in enumerate(metrics):\n",
    "        plt.bar(index + i * bar_width, results_df[metric], bar_width, label=metric)\n",
    "\n",
    "    plt.xlabel('Stage (Model Combination)')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Comparison of Stacked Model Performance by Metric')\n",
    "    plt.xticks(index + bar_width * (len(metrics) - 1) / 2, stages)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    preprocessor = DataPreprocessor('./data/경진대회용 주조 공정최적화 데이터셋.csv')\n",
    "    preprocessor.encode_working()\n",
    "    preprocessor.preprocess_datetime()\n",
    "    preprocessor.remove_unnecessary_columns()\n",
    "    preprocessor.remove_missing_values()\n",
    "    preprocessor.remove_outliers()\n",
    "    preprocessor.perform_feature_selection()\n",
    "    data = preprocessor.get_processed_data()\n",
    "\n",
    "    X = data.drop('passorfail', axis=1)\n",
    "    y = data['passorfail']\n",
    "\n",
    "    stacker1 = EnsembleStacker1(X, y)\n",
    "    stacker2 = EnsembleStacker2(X, y)\n",
    "    stacker3 = EnsembleStacker3(X, y)\n",
    "\n",
    "    results_df1 = stacker1.run_all_combinations()\n",
    "    print(\"\\n전체 조합 성능 비교:\")\n",
    "    print(results_df1)\n",
    "\n",
    "    # 스태킹 모델 성능 시각화\n",
    "    plot_stacked_model_performance(results_df1)\n",
    "\n",
    "\n",
    "    results_df2 = stacker2.run_all_combinations()\n",
    "    print(\"\\n전체 조합 성능 비교:\")\n",
    "    print(results_df2)\n",
    "\n",
    "    # 스태킹 모델 성능 시각화\n",
    "    plot_stacked_model_performance(results_df2)\n",
    "\n",
    "    results_df3 = stacker3.run_all_combinations()\n",
    "    print(\"\\n전체 조합 성능 비교:\")\n",
    "    print(results_df3)\n",
    "\n",
    "    # 스태킹 모델 성능 시각화\n",
    "    plot_stacked_model_performance(results_df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df1.to_csv(\"./result/results1.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "results_df2.to_csv(\"./result/results2.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "results_df3.to_csv(\"./result/results3.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
